{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import librosa\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "# For preprocessing\n",
    "import wave\n",
    "import os\n",
    "\n",
    "# for avoiding bad audio files\n",
    "from soundfile import LibsndfileError, SoundFileRuntimeError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading in raw input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20957\n"
     ]
    }
   ],
   "source": [
    "# Load in the data from the specified directory\n",
    "raw_train_files = glob('train/*')\n",
    "\n",
    "# Load the audio file using librosa\n",
    "# y = audio time series\n",
    "\n",
    "# Method for splits valid data files\n",
    "def split_data(input_dir, output_dir, segment_duration):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    for root, dirs, files in os.walk(input_dir):\n",
    "        for file in files:\n",
    "            if file.endswith('.wav'):\n",
    "                input_file = os.path.join(root, file)\n",
    "                try:\n",
    "                    with wave.open(input_file, 'rb') as wf:\n",
    "                        framerate = wf.getframerate()\n",
    "                        nframes = wf.getnframes()\n",
    "                        # Gets the full length of the audio in seconds\n",
    "                        duration = nframes / framerate\n",
    "\n",
    "                        # Calc frames per seg\n",
    "                        frames_per_seg = int(segment_duration * framerate)\n",
    "                        num_segments = 26\n",
    "\n",
    "                        # split the file into segments\n",
    "                        for i in range(num_segments):\n",
    "                            start_frame = i * frames_per_seg\n",
    "                            end_frame = (i + 1) * frames_per_seg\n",
    "                            \n",
    "                            # set position at time we want\n",
    "                            wf.setpos(i * framerate)\n",
    "                            # Read audio data for this segment\n",
    "                            segment_data = wf.readframes(frames_per_seg)\n",
    "\n",
    "                            # Write the segment to a new file\n",
    "                            output_file = os.path.join(output_dir, f'{os.path.splitext(os.path.basename(input_file))[0]}_segment_{i}.wav')\n",
    "                            with wave.open(output_file, 'wb') as segment_wf:\n",
    "                                segment_wf.setparams(wf.getparams())\n",
    "                                segment_wf.writeframes(segment_data)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error splitting audio file {input_file}: {e}\")\n",
    "    return output_dir\n",
    "\n",
    "train_files_dir = split_data(\"train\", \"split_output\", 5)\n",
    "train_files = glob(train_files_dir + \"/*\")\n",
    "print(len(train_files))\n",
    "time_series = []\n",
    "#load the files from the directory\n",
    "for filename in train_files:\n",
    "    try:\n",
    "        y, _ = librosa.load(filename)\n",
    "        # print(\"Iteration \" + str(i) + \" success\")\n",
    "        time_series.append(y)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading audio file {filename}: {e}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(series):\n",
    "    \"\"\"\n",
    "    Uses Librosa to extract features from the time series.\n",
    "    series: list of floats\n",
    "    returns:\n",
    "    spectral_centroid: the center of mass of the spectrum\n",
    "    spectral rolloff: the frequency below which 85% of the magnitude distribution is concentrated\n",
    "    spectral bandwidth: the width of the band of frequencies\n",
    "    spectral contrast: the difference in amplitude between peaks and valleys in the spectrum\n",
    "    spectral flatness: the flatness of a signal\n",
    "    spectral rms: the root mean square of the signal\n",
    "    \"\"\"\n",
    "    sr = 22050\n",
    "    spectral_centroid = librosa.feature.spectral_centroid(y=series)\n",
    "    spectral_rolloff = librosa.feature.spectral_rolloff(y=series)\n",
    "    spectral_bandwidth = librosa.feature.spectral_bandwidth(y=series)\n",
    "    spectral_contrast = librosa.feature.spectral_contrast(y=series)\n",
    "    spectral_flatness = librosa.feature.spectral_flatness(y=series)\n",
    "    rms = librosa.feature.rms(y=series)\n",
    "    onset_env = librosa.onset.onset_strength(y=series, sr=sr)\n",
    "    tempo, beats = librosa.beat.beat_track(y =series, sr=sr)\n",
    "    beat_strengths = onset_env[beats]\n",
    "    key = librosa.feature.chroma_stft(y=series, sr=sr)\n",
    "\n",
    "    return spectral_centroid, spectral_rolloff, spectral_bandwidth, spectral_contrast, spectral_flatness, rms, tempo, beat_strengths, key\n",
    "\n",
    "# centroids = []\n",
    "# rolloffs = []\n",
    "# bandwidths = []\n",
    "# contrasts = []\n",
    "# flatnesses = []\n",
    "# rms = []\n",
    "# tempos = []\n",
    "# beat_strengths = []\n",
    "# keys = []\n",
    "\n",
    "\n",
    "# for i in range(0, len(time_series)):\n",
    "#     spectral_centroid, spectral_rolloff, spectral_bandwidth, spectral_contrast, spectral_flatness, spectral_rms, tempo, beat_strength, key = extract_features(time_series[i])\n",
    "#     centroids.append(spectral_centroid)\n",
    "#     rolloffs.append(spectral_rolloff)\n",
    "#     bandwidths.append(spectral_bandwidth)\n",
    "#     contrasts.append(spectral_contrast)\n",
    "#     flatnesses.append(spectral_flatness)\n",
    "#     rms.append(spectral_rms)\n",
    "#     tempos.append(tempo)\n",
    "#     beat_strengths.append(beat_strength)\n",
    "#     keys.append(key)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_MORE_features(series):\n",
    "    \"\"\"\n",
    "    Uses Librosa to extract features from the time series.\n",
    "    series: list of floats\n",
    "    returns:\n",
    "    zero_crossing_rate: the rate of sign changes in the signal\n",
    "    mfcc: Mel-frequency cepstral coefficients\n",
    "    \"\"\"\n",
    "    zero_rate = librosa.feature.zero_crossing_rate(y=series)\n",
    "    mfcc = librosa.feature.mfcc(y=series)\n",
    "\n",
    "\n",
    "    return zero_rate, mfcc\n",
    "\n",
    "# zero_rates = []\n",
    "# mfccs = []\n",
    "\n",
    "# for i in range(0, len(time_series)):\n",
    "#     zero_rate, mfcc = extract_MORE_features(time_series[i])\n",
    "#     zero_rates.append(zero_rate)\n",
    "#     mfccs.append(mfcc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect Features into data matrix ( we are only using some from before, but you can use whichever ones you want)\n",
    "spectral_centroid, spectral_rolloff, spectral_bandwidth, spectral_contrast, spectral_flatness, spectral_rms, tempo, beat_strength, key = extract_features(time_series[0])\n",
    "zero_rate, mfcc = extract_MORE_features(time_series[0])\n",
    "feature = np.concatenate((np.ravel(spectral_centroid), np.ravel(spectral_rolloff), np.ravel(spectral_bandwidth), np.ravel(spectral_contrast), np.ravel(spectral_flatness), np.ravel(spectral_rms), np.ravel(tempo), np.ravel(beat_strength), np.ravel(key), np.ravel(zero_rate), np.ravel(mfcc)))\n",
    "for i in range(1, len(time_series)):\n",
    "    spectral_centroid, spectral_rolloff, spectral_bandwidth, spectral_contrast, spectral_flatness, spectral_rms, tempo, beat_strength, key = extract_features(time_series[i])\n",
    "    zero_rate, mfcc = extract_MORE_features(time_series[i])\n",
    "    feature_to_add = np.concatenate((np.ravel(spectral_centroid), np.ravel(spectral_rolloff), np.ravel(spectral_bandwidth), np.ravel(spectral_contrast), np.ravel(spectral_flatness), np.ravel(spectral_rms), np.ravel(tempo), np.ravel(beat_strength), np.ravel(key), np.ravel(zero_rate), np.ravel(mfcc)))\n",
    "    feature = np.hstack((feature, feature_to_add))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components = 100)\n",
    "new_feature = pca.fit_transform(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, SimpleRNN, Conv2D, MaxPooling2D, Flatten\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_validate\n",
    "from scipy.stats import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for i in range(0, len(time_series)):\n",
    "    data.append(librosa.feature.melspectrogram(y=time_series[i], sr=22050))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_9\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_9\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">124</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">212</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">41</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">70</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">66</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">882</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,232</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">84</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">850</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,816</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">7,740</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_25 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m124\u001b[0m, \u001b[38;5;34m212\u001b[0m, \u001b[38;5;34m5\u001b[0m)    │           \u001b[38;5;34m130\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_17 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m41\u001b[0m, \u001b[38;5;34m70\u001b[0m, \u001b[38;5;34m5\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_26 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m37\u001b[0m, \u001b[38;5;34m66\u001b[0m, \u001b[38;5;34m7\u001b[0m)      │           \u001b[38;5;34m882\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_18 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m7\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_27 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m7\u001b[0m)       │         \u001b[38;5;34m1,232\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_19 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m7\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_7 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m84\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_28 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m850\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_29 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m2,816\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_30 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_31 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m)             │         \u001b[38;5;34m7,740\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">46,546</span> (181.82 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m46,546\u001b[0m (181.82 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">46,546</span> (181.82 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m46,546\u001b[0m (181.82 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'accuracy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[55], line 26\u001b[0m\n\u001b[0;32m     21\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# model.fit(features_train, y_train, epochs=25, batch_size=28, validation_split=0.2, verbose=2, shuffle=True, steps_per_epoch=10, validation_steps=10, validation_batch_size=28, validation_freq=1)\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# loss, accuracy = model.evaluate(features_train, y_train)\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNeural Network accuracy:\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[43maccuracy\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'accuracy' is not defined"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(5, (5, 5), activation='relu', input_shape=(128, 216, 1)))\n",
    "model.add(MaxPooling2D((3, 3)))\n",
    "model.add(Conv2D(7, (5, 5), activation='relu'))\n",
    "model.add(MaxPooling2D((3, 3)))\n",
    "model.add(Conv2D(7, (5, 5), activation='relu'))\n",
    "model.add(MaxPooling2D((3, 3)))\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(10, activation='relu', input_shape = (65,), kernel_regularizer='l2', bias_regularizer='l2', activity_regularizer='l2'))\n",
    "\n",
    "model.add(Dense(256, activation='relu'))\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "\n",
    "model.add(Dense(60, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# model.fit(features_train, y_train, epochs=25, batch_size=28, validation_split=0.2, verbose=2, shuffle=True, steps_per_epoch=10, validation_steps=10, validation_batch_size=28, validation_freq=1)\n",
    "\n",
    "# loss, accuracy = model.evaluate(features_train, y_train)\n",
    "print('Neural Network accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export the Feature data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_features(features):\n",
    "    \"\"\"\n",
    "    stores the mean, standard deviation, max, and min of the features\n",
    "    \"\"\"\n",
    "    means = []\n",
    "    stds = []\n",
    "    maxs = []\n",
    "    mins = []\n",
    "    for feature in features:\n",
    "        means.append(np.mean(feature))\n",
    "        stds.append(np.std(feature))\n",
    "        maxs.append(np.max(feature))\n",
    "        mins.append(np.min(feature))\n",
    "    return means, stds, maxs, mins\n",
    "\n",
    "def save_features(features, filename):\n",
    "    \"\"\"\n",
    "    saves the features to a csv file\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame({filename: features})\n",
    "    df.to_csv('features_test/' + filename + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregates = []\n",
    "for feature in features:\n",
    "    mean, std, max, min = aggregate_features(feature)\n",
    "    aggregates.append(mean)\n",
    "    aggregates.append(std)\n",
    "    aggregates.append(max)\n",
    "    aggregates.append(min)\n",
    "aggregates.append(tempos)\n",
    "feature_count = 0\n",
    "for aggregate in aggregates:\n",
    "    save_features(aggregate, 'feature_' + str(feature_count))\n",
    "    feature_count += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evenMOREfeatures(series):\n",
    "    \"\"\"\n",
    "    Uses Librosa to extract features from the time series.\n",
    "    series: list of floats\n",
    "    returns:\n",
    "    chroma: the chroma of the signal\n",
    "    \"\"\"\n",
    "    tonnetz = librosa.feature.tonnetz(y=series)\n",
    "    chroma = librosa.feature.chroma_stft(y=series)\n",
    "    harmonic, percussive = librosa.effects.hpss(y=series)\n",
    "    harmonic_chroma = librosa.feature.chroma_cqt(y=harmonic)\n",
    "    percussive_tempo, _ = librosa.beat.beat_track(y=percussive)\n",
    "\n",
    "    return tonnetz, chroma, harmonic_chroma, percussive_tempo\n",
    "\n",
    "tonnetzs = []\n",
    "chromas = []\n",
    "harmonic_chromas = []\n",
    "percussive_tempos = []\n",
    "\n",
    "for i in range(0, len(time_series)):\n",
    "    tonnetz, chroma, harmonic_chroma, percussive_tempo = evenMOREfeatures(time_series[i])\n",
    "    tonnetzs.append(tonnetz)\n",
    "    chromas.append(chroma)\n",
    "    harmonic_chromas.append(harmonic_chroma)\n",
    "    percussive_tempos.append(percussive_tempo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregate_more = []\n",
    "for feature in [tonnetzs, chromas, harmonic_chromas, percussive_tempos]:\n",
    "    mean, std, max, min = aggregate_features(feature)\n",
    "    aggregate_more.append(mean)\n",
    "    aggregate_more.append(std)\n",
    "    aggregate_more.append(max)\n",
    "    aggregate_more.append(min)\n",
    "    \n",
    "for aggregate in aggregate_more:\n",
    "    save_features(aggregate, 'feature_' + str(i))\n",
    "    feature_count += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def more_features(series):\n",
    "    \"\"\"\n",
    "    Uses Librosa to extract features from the time series.\n",
    "    series: list of floats\n",
    "    returns:\n",
    "    mfcc_delta: the change in mfcc\n",
    "    \"\"\"\n",
    "    mfcc_delta = librosa.feature.delta(librosa.feature.mfcc(y=series))\n",
    "\n",
    "    return mfcc_delta\n",
    "\n",
    "mfcc_deltas = []\n",
    "\n",
    "for i in range(0, len(time_series)):\n",
    "    mfcc_delta = more_features(time_series[i])\n",
    "    mfcc_deltas.append(mfcc_delta)\n",
    "\n",
    "aggregate_mfcc_delta = []\n",
    "for feature in [mfcc_deltas]:\n",
    "    mean, std, max, min = aggregate_features(feature)\n",
    "    aggregate_mfcc_delta.append(mean)\n",
    "    aggregate_mfcc_delta.append(std)\n",
    "    aggregate_mfcc_delta.append(max)\n",
    "    aggregate_mfcc_delta.append(min)\n",
    "feature_count = 61\n",
    "for aggregate in aggregate_mfcc_delta:\n",
    "    save_features(aggregate, 'feature_' + str(feature_count))\n",
    "    feature_count += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
