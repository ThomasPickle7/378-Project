{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import librosa\n",
    "\n",
    "# For preprocessing\n",
    "import wave\n",
    "import os\n",
    "\n",
    "# for avoiding bad audio files\n",
    "from soundfile import LibsndfileError, SoundFileRuntimeError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading in raw input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error splitting audio file train/train312.wav: file does not start with RIFF id\n"
     ]
    }
   ],
   "source": [
    "# Load in the data from the specified directory\n",
    "raw_train_files = glob('train/*')\n",
    "\n",
    "# Load the audio file using librosa\n",
    "# y = audio time series\n",
    "\n",
    "# Method for splits valid data files\n",
    "def split_data(input_dir, output_dir, segment_duration):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    for root, dirs, files in os.walk(input_dir):\n",
    "        for file in files:\n",
    "            if file.endswith('.wav'):\n",
    "                input_file = os.path.join(root, file)\n",
    "                try:\n",
    "                    with wave.open(input_file, 'rb') as wf:\n",
    "                        framerate = wf.getframerate()\n",
    "                        nframes = wf.getnframes()\n",
    "                        # Gets the full length of the audio in seconds\n",
    "                        duration = nframes / framerate\n",
    "\n",
    "                        # Calc frames per seg\n",
    "                        frames_per_seg = int(segment_duration * framerate)\n",
    "                        num_segments = int(duration / segment_duration)\n",
    "\n",
    "                        # split the file into segments\n",
    "                        for i in range(num_segments):\n",
    "                            start_frame = i * frames_per_seg\n",
    "                            end_frame = (i + 1) * frames_per_seg\n",
    "\n",
    "                            # Read audio data for this segment\n",
    "                            segment_data = wf.readframes(frames_per_seg)\n",
    "\n",
    "                            # Write the segment to a new file\n",
    "                            output_file = os.path.join(output_dir, f'{os.path.splitext(os.path.basename(input_file))[0]}_segment_{i}.wav')\n",
    "                            with wave.open(output_file, 'wb') as segment_wf:\n",
    "                                segment_wf.setparams(wf.getparams())\n",
    "                                segment_wf.writeframes(segment_data)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error splitting audio file {input_file}: {e}\")\n",
    "    return output_dir\n",
    "\n",
    "train_files_dir = split_data(\"train\", \"split_output\", 5)\n",
    "train_files = glob(train_files_dir + \"/*\")\n",
    "time_series = []\n",
    "#load the files from the directory\n",
    "for filename in train_files:\n",
    "    try:\n",
    "        y, _ = librosa.load(filename)\n",
    "        # print(\"Iteration \" + str(i) + \" success\")\n",
    "        time_series.append(y)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading audio file {filename}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.02783203  0.03942871  0.01895142 ...  0.04376221  0.04745483\n",
      "  0.00982666]\n",
      "110250\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "800",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/indexes/range.py:413\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 413\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_range\u001b[38;5;241m.\u001b[39mindex(new_key)\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[0;31mValueError\u001b[0m: 800 is not in range",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m start_time \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m26\u001b[39m):\n\u001b[1;32m     12\u001b[0m     new_time_series\u001b[38;5;241m.\u001b[39mappend(time_series[index][start_time \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m22050\u001b[39m : (start_time \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m5\u001b[39m) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m22050\u001b[39m])\n\u001b[0;32m---> 13\u001b[0m     new_labels\u001b[38;5;241m.\u001b[39mappend(\u001b[43my_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/series.py:1121\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[1;32m   1120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m-> 1121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1123\u001b[0m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[1;32m   1124\u001b[0m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[1;32m   1125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/series.py:1237\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[1;32m   1236\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1237\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[1;32m   1240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/indexes/range.py:415\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_range\u001b[38;5;241m.\u001b[39mindex(new_key)\n\u001b[1;32m    414\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m--> 415\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Hashable):\n\u001b[1;32m    417\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 800"
     ]
    }
   ],
   "source": [
    "# print(time_series)\n",
    "print(time_series[0])\n",
    "print(len(time_series[0]))\n",
    "# Method to break up data into smaller parts\n",
    "\n",
    "new_time_series = []\n",
    "new_labels = []\n",
    "train = pd.read_csv('train.csv')\n",
    "y_train = train['Genre']\n",
    "for index in range(len(time_series)):\n",
    "    for start_time in range(26):\n",
    "        new_time_series.append(time_series[index][start_time * 22050 : (start_time + 5) * 22050])\n",
    "        new_labels.append(y_train[index])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(series):\n",
    "    \"\"\"\n",
    "    Uses Librosa to extract features from the time series.\n",
    "    series: list of floats\n",
    "    returns:\n",
    "    spectral_centroid: the center of mass of the spectrum\n",
    "    spectral rolloff: the frequency below which 85% of the magnitude distribution is concentrated\n",
    "    spectral bandwidth: the width of the band of frequencies\n",
    "    spectral contrast: the difference in amplitude between peaks and valleys in the spectrum\n",
    "    spectral flatness: the flatness of a signal\n",
    "    spectral rms: the root mean square of the signal\n",
    "    \"\"\"\n",
    "    sr = 22050\n",
    "    spectral_centroid = librosa.feature.spectral_centroid(y=series)\n",
    "    spectral_rolloff = librosa.feature.spectral_rolloff(y=series)\n",
    "    spectral_bandwidth = librosa.feature.spectral_bandwidth(y=series)\n",
    "    spectral_contrast = librosa.feature.spectral_contrast(y=series)\n",
    "    spectral_flatness = librosa.feature.spectral_flatness(y=series)\n",
    "    rms = librosa.feature.rms(y=series)\n",
    "    onset_env = librosa.onset.onset_strength(y=series, sr=sr)\n",
    "    tempo, beats = librosa.beat.beat_track(y =series, sr=sr)\n",
    "    beat_strengths = onset_env[beats]\n",
    "    key = librosa.feature.chroma_stft(y=series, sr=sr)\n",
    "\n",
    "    return spectral_centroid, spectral_rolloff, spectral_bandwidth, spectral_contrast, spectral_flatness, rms, tempo, beat_strengths, key\n",
    "\n",
    "centroids = []\n",
    "rolloffs = []\n",
    "bandwidths = []\n",
    "contrasts = []\n",
    "flatnesses = []\n",
    "rms = []\n",
    "tempos = []\n",
    "beat_strengths = []\n",
    "keys = []\n",
    "\n",
    "\n",
    "for i in range(0, len(time_series)):\n",
    "    spectral_centroid, spectral_rolloff, spectral_bandwidth, spectral_contrast, spectral_flatness, spectral_rms, tempo, beat_strength, key = extract_features(time_series[i])\n",
    "    centroids.append(spectral_centroid)\n",
    "    rolloffs.append(spectral_rolloff)\n",
    "    bandwidths.append(spectral_bandwidth)\n",
    "    contrasts.append(spectral_contrast)\n",
    "    flatnesses.append(spectral_flatness)\n",
    "    rms.append(spectral_rms)\n",
    "    tempos.append(tempo)\n",
    "    beat_strengths.append(beat_strength)\n",
    "    keys.append(key)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_MORE_features(series):\n",
    "    \"\"\"\n",
    "    Uses Librosa to extract features from the time series.\n",
    "    series: list of floats\n",
    "    returns:\n",
    "    zero_crossing_rate: the rate of sign changes in the signal\n",
    "    mfcc: Mel-frequency cepstral coefficients\n",
    "    \"\"\"\n",
    "    zero_rate = librosa.feature.zero_crossing_rate(y=series)\n",
    "    mfcc = librosa.feature.mfcc(y=series)\n",
    "\n",
    "\n",
    "    return zero_rate, mfcc\n",
    "\n",
    "zero_rates = []\n",
    "mfccs = []\n",
    "\n",
    "for i in range(0, len(time_series)):\n",
    "    zero_rate, mfcc = extract_MORE_features(time_series[i])\n",
    "    zero_rates.append(zero_rate)\n",
    "    mfccs.append(mfcc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         1.         0.38291848 ... 0.43263552 0.37777305 0.39717636]\n",
      " [0.22910109 0.20459473 0.08079255 ... 0.28775373 0.22603354 0.26838958]\n",
      " [0.03219749 0.03264437 0.0251236  ... 0.37318882 0.22551163 0.20922756]\n",
      " ...\n",
      " [0.72905344 0.95025206 1.         ... 0.8150928  0.83707166 0.9120585 ]\n",
      " [0.3821179  0.4050591  0.38146168 ... 1.         1.         1.        ]\n",
      " [0.25871077 0.20428272 0.09758538 ... 0.59401184 0.5136056  0.49116886]]\n"
     ]
    }
   ],
   "source": [
    "features =[centroids, rolloffs, bandwidths, contrasts, flatnesses, rms, tempos, beat_strengths, keys, zero_rates, mfccs]\n",
    "print(keys[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export the Feature data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_features(features):\n",
    "    \"\"\"\n",
    "    stores the mean, standard deviation, max, and min of the features\n",
    "    \"\"\"\n",
    "    means = []\n",
    "    stds = []\n",
    "    maxs = []\n",
    "    mins = []\n",
    "    for feature in features:\n",
    "        means.append(np.mean(feature))\n",
    "        stds.append(np.std(feature))\n",
    "        maxs.append(np.max(feature))\n",
    "        mins.append(np.min(feature))\n",
    "    return means, stds, maxs, mins\n",
    "\n",
    "def save_features(features, filename):\n",
    "    \"\"\"\n",
    "    saves the features to a csv file\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame({filename: features})\n",
    "    df.to_csv('features_test/' + filename + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregates = []\n",
    "for feature in features:\n",
    "    mean, std, max, min = aggregate_features(feature)\n",
    "    aggregates.append(mean)\n",
    "    aggregates.append(std)\n",
    "    aggregates.append(max)\n",
    "    aggregates.append(min)\n",
    "aggregates.append(tempos)\n",
    "feature_count = 0\n",
    "for aggregate in aggregates:\n",
    "    save_features(aggregate, 'feature_' + str(feature_count))\n",
    "    feature_count += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evenMOREfeatures(series):\n",
    "    \"\"\"\n",
    "    Uses Librosa to extract features from the time series.\n",
    "    series: list of floats\n",
    "    returns:\n",
    "    chroma: the chroma of the signal\n",
    "    \"\"\"\n",
    "    tonnetz = librosa.feature.tonnetz(y=series)\n",
    "    chroma = librosa.feature.chroma_stft(y=series)\n",
    "    harmonic, percussive = librosa.effects.hpss(y=series)\n",
    "    harmonic_chroma = librosa.feature.chroma_cqt(y=harmonic)\n",
    "    percussive_tempo, _ = librosa.beat.beat_track(y=percussive)\n",
    "\n",
    "    return tonnetz, chroma, harmonic_chroma, percussive_tempo\n",
    "\n",
    "tonnetzs = []\n",
    "chromas = []\n",
    "harmonic_chromas = []\n",
    "percussive_tempos = []\n",
    "\n",
    "for i in range(0, len(time_series)):\n",
    "    tonnetz, chroma, harmonic_chroma, percussive_tempo = evenMOREfeatures(time_series[i])\n",
    "    tonnetzs.append(tonnetz)\n",
    "    chromas.append(chroma)\n",
    "    harmonic_chromas.append(harmonic_chroma)\n",
    "    percussive_tempos.append(percussive_tempo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregate_more = []\n",
    "for feature in [tonnetzs, chromas, harmonic_chromas, percussive_tempos]:\n",
    "    mean, std, max, min = aggregate_features(feature)\n",
    "    aggregate_more.append(mean)\n",
    "    aggregate_more.append(std)\n",
    "    aggregate_more.append(max)\n",
    "    aggregate_more.append(min)\n",
    "    \n",
    "for aggregate in aggregate_more:\n",
    "    save_features(aggregate, 'feature_' + str(i))\n",
    "    feature_count += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def more_features(series):\n",
    "    \"\"\"\n",
    "    Uses Librosa to extract features from the time series.\n",
    "    series: list of floats\n",
    "    returns:\n",
    "    mfcc_delta: the change in mfcc\n",
    "    \"\"\"\n",
    "    mfcc_delta = librosa.feature.delta(librosa.feature.mfcc(y=series))\n",
    "\n",
    "    return mfcc_delta\n",
    "\n",
    "mfcc_deltas = []\n",
    "\n",
    "for i in range(0, len(time_series)):\n",
    "    mfcc_delta = more_features(time_series[i])\n",
    "    mfcc_deltas.append(mfcc_delta)\n",
    "\n",
    "aggregate_mfcc_delta = []\n",
    "for feature in [mfcc_deltas]:\n",
    "    mean, std, max, min = aggregate_features(feature)\n",
    "    aggregate_mfcc_delta.append(mean)\n",
    "    aggregate_mfcc_delta.append(std)\n",
    "    aggregate_mfcc_delta.append(max)\n",
    "    aggregate_mfcc_delta.append(min)\n",
    "feature_count = 61\n",
    "for aggregate in aggregate_mfcc_delta:\n",
    "    save_features(aggregate, 'feature_' + str(feature_count))\n",
    "    feature_count += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
