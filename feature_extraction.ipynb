{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import librosa\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "# For preprocessing\n",
    "import wave\n",
    "import os\n",
    "\n",
    "# for avoiding bad audio files\n",
    "from soundfile import LibsndfileError, SoundFileRuntimeError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading in raw input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20957\n"
     ]
    }
   ],
   "source": [
    "# Load in the data from the specified directory\n",
    "raw_train_files = glob('train/*')\n",
    "\n",
    "# Load the audio file using librosa\n",
    "# y = audio time series\n",
    "\n",
    "# Method for splits valid data files\n",
    "def split_data(input_dir, output_dir, segment_duration):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    for root, dirs, files in os.walk(input_dir):\n",
    "        for file in files:\n",
    "            if file.endswith('.wav'):\n",
    "                input_file = os.path.join(root, file)\n",
    "                try:\n",
    "                    with wave.open(input_file, 'rb') as wf:\n",
    "                        framerate = wf.getframerate()\n",
    "                        nframes = wf.getnframes()\n",
    "                        # Gets the full length of the audio in seconds\n",
    "                        duration = nframes / framerate\n",
    "\n",
    "                        # Calc frames per seg\n",
    "                        frames_per_seg = int(segment_duration * framerate)\n",
    "                        num_segments = 26\n",
    "\n",
    "                        # split the file into segments\n",
    "                        for i in range(num_segments):\n",
    "                            start_frame = i * frames_per_seg\n",
    "                            end_frame = (i + 1) * frames_per_seg\n",
    "                            \n",
    "                            # set position at time we want\n",
    "                            wf.setpos(i * framerate)\n",
    "                            # Read audio data for this segment\n",
    "                            segment_data = wf.readframes(frames_per_seg)\n",
    "\n",
    "                            # Write the segment to a new file\n",
    "                            output_file = os.path.join(output_dir, f'{os.path.splitext(os.path.basename(input_file))[0]}_segment_{i}.wav')\n",
    "                            with wave.open(output_file, 'wb') as segment_wf:\n",
    "                                segment_wf.setparams(wf.getparams())\n",
    "                                segment_wf.writeframes(segment_data)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error splitting audio file {input_file}: {e}\")\n",
    "    return output_dir\n",
    "\n",
    "train_files_dir = split_data(\"train\", \"split_output\", 5)\n",
    "train_files = glob(train_files_dir + \"/*\")\n",
    "print(len(train_files))\n",
    "time_series = []\n",
    "#load the files from the directory\n",
    "for filename in train_files:\n",
    "    try:\n",
    "        y, _ = librosa.load(filename)\n",
    "        # print(\"Iteration \" + str(i) + \" success\")\n",
    "        time_series.append(y)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading audio file {filename}: {e}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(time_series)\n",
    "# print(time_series[0])\n",
    "# print(len(time_series[0]))\n",
    "# Method to break up data into smaller parts\n",
    "\n",
    "new_time_series = []\n",
    "new_labels = []\n",
    "train = pd.read_csv('train.csv')\n",
    "y_train = train['Genre']\n",
    "for index in range(len(time_series)):\n",
    "    for start_time in range(26):\n",
    "        new_time_series.append(time_series[index][start_time * 22050 : (start_time + 5) * 22050])\n",
    "        new_labels.append(y_train[index])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(series):\n",
    "    \"\"\"\n",
    "    Uses Librosa to extract features from the time series.\n",
    "    series: list of floats\n",
    "    returns:\n",
    "    spectral_centroid: the center of mass of the spectrum\n",
    "    spectral rolloff: the frequency below which 85% of the magnitude distribution is concentrated\n",
    "    spectral bandwidth: the width of the band of frequencies\n",
    "    spectral contrast: the difference in amplitude between peaks and valleys in the spectrum\n",
    "    spectral flatness: the flatness of a signal\n",
    "    spectral rms: the root mean square of the signal\n",
    "    \"\"\"\n",
    "    sr = 22050\n",
    "    spectral_centroid = librosa.feature.spectral_centroid(y=series)\n",
    "    spectral_rolloff = librosa.feature.spectral_rolloff(y=series)\n",
    "    spectral_bandwidth = librosa.feature.spectral_bandwidth(y=series)\n",
    "    spectral_contrast = librosa.feature.spectral_contrast(y=series)\n",
    "    spectral_flatness = librosa.feature.spectral_flatness(y=series)\n",
    "    rms = librosa.feature.rms(y=series)\n",
    "    onset_env = librosa.onset.onset_strength(y=series, sr=sr)\n",
    "    tempo, beats = librosa.beat.beat_track(y =series, sr=sr)\n",
    "    beat_strengths = onset_env[beats]\n",
    "    key = librosa.feature.chroma_stft(y=series, sr=sr)\n",
    "\n",
    "    return spectral_centroid, spectral_rolloff, spectral_bandwidth, spectral_contrast, spectral_flatness, rms, tempo, beat_strengths, key\n",
    "\n",
    "# centroids = []\n",
    "# rolloffs = []\n",
    "# bandwidths = []\n",
    "# contrasts = []\n",
    "# flatnesses = []\n",
    "# rms = []\n",
    "# tempos = []\n",
    "# beat_strengths = []\n",
    "# keys = []\n",
    "\n",
    "\n",
    "# for i in range(0, len(time_series)):\n",
    "#     spectral_centroid, spectral_rolloff, spectral_bandwidth, spectral_contrast, spectral_flatness, spectral_rms, tempo, beat_strength, key = extract_features(time_series[i])\n",
    "#     centroids.append(spectral_centroid)\n",
    "#     rolloffs.append(spectral_rolloff)\n",
    "#     bandwidths.append(spectral_bandwidth)\n",
    "#     contrasts.append(spectral_contrast)\n",
    "#     flatnesses.append(spectral_flatness)\n",
    "#     rms.append(spectral_rms)\n",
    "#     tempos.append(tempo)\n",
    "#     beat_strengths.append(beat_strength)\n",
    "#     keys.append(key)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_MORE_features(series):\n",
    "    \"\"\"\n",
    "    Uses Librosa to extract features from the time series.\n",
    "    series: list of floats\n",
    "    returns:\n",
    "    zero_crossing_rate: the rate of sign changes in the signal\n",
    "    mfcc: Mel-frequency cepstral coefficients\n",
    "    \"\"\"\n",
    "    zero_rate = librosa.feature.zero_crossing_rate(y=series)\n",
    "    mfcc = librosa.feature.mfcc(y=series)\n",
    "\n",
    "\n",
    "    return zero_rate, mfcc\n",
    "\n",
    "# zero_rates = []\n",
    "# mfccs = []\n",
    "\n",
    "# for i in range(0, len(time_series)):\n",
    "#     zero_rate, mfcc = extract_MORE_features(time_series[i])\n",
    "#     zero_rates.append(zero_rate)\n",
    "#     mfccs.append(mfcc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features =[centroids, rolloffs, bandwidths, contrasts, flatnesses, rms, tempos, beat_strengths, keys, zero_rates, mfccs]\n",
    "print(keys[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect Features into data matrix ( we are only using some from before, but you can use whichever ones you want)\n",
    "spectral_centroid, spectral_rolloff, spectral_bandwidth, spectral_contrast, spectral_flatness, spectral_rms, tempo, beat_strength, key = extract_features(time_series[0])\n",
    "zero_rate, mfcc = extract_MORE_features(time_series[0])\n",
    "feature = np.concatenate((np.ravel(spectral_centroid), np.ravel(spectral_rolloff), np.ravel(spectral_bandwidth), np.ravel(spectral_contrast), np.ravel(spectral_flatness), np.ravel(spectral_rms), np.ravel(tempo), np.ravel(beat_strength), np.ravel(key), np.ravel(zero_rate), np.ravel(mfcc)))\n",
    "for i in range(1, len(time_series)):\n",
    "    spectral_centroid, spectral_rolloff, spectral_bandwidth, spectral_contrast, spectral_flatness, spectral_rms, tempo, beat_strength, key = extract_features(time_series[i])\n",
    "    zero_rate, mfcc = extract_MORE_features(time_series[i])\n",
    "    feature_to_add = np.concatenate((np.ravel(spectral_centroid), np.ravel(spectral_rolloff), np.ravel(spectral_bandwidth), np.ravel(spectral_contrast), np.ravel(spectral_flatness), np.ravel(spectral_rms), np.ravel(tempo), np.ravel(beat_strength), np.ravel(key), np.ravel(zero_rate), np.ravel(mfcc)))\n",
    "    feature = np.hstack((feature, feature_to_add))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components = 100)\n",
    "new_feature = pca.fit_transform(feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export the Feature data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_features(features):\n",
    "    \"\"\"\n",
    "    stores the mean, standard deviation, max, and min of the features\n",
    "    \"\"\"\n",
    "    means = []\n",
    "    stds = []\n",
    "    maxs = []\n",
    "    mins = []\n",
    "    for feature in features:\n",
    "        means.append(np.mean(feature))\n",
    "        stds.append(np.std(feature))\n",
    "        maxs.append(np.max(feature))\n",
    "        mins.append(np.min(feature))\n",
    "    return means, stds, maxs, mins\n",
    "\n",
    "def save_features(features, filename):\n",
    "    \"\"\"\n",
    "    saves the features to a csv file\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame({filename: features})\n",
    "    df.to_csv('features_test/' + filename + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregates = []\n",
    "for feature in features:\n",
    "    mean, std, max, min = aggregate_features(feature)\n",
    "    aggregates.append(mean)\n",
    "    aggregates.append(std)\n",
    "    aggregates.append(max)\n",
    "    aggregates.append(min)\n",
    "aggregates.append(tempos)\n",
    "feature_count = 0\n",
    "for aggregate in aggregates:\n",
    "    save_features(aggregate, 'feature_' + str(feature_count))\n",
    "    feature_count += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evenMOREfeatures(series):\n",
    "    \"\"\"\n",
    "    Uses Librosa to extract features from the time series.\n",
    "    series: list of floats\n",
    "    returns:\n",
    "    chroma: the chroma of the signal\n",
    "    \"\"\"\n",
    "    tonnetz = librosa.feature.tonnetz(y=series)\n",
    "    chroma = librosa.feature.chroma_stft(y=series)\n",
    "    harmonic, percussive = librosa.effects.hpss(y=series)\n",
    "    harmonic_chroma = librosa.feature.chroma_cqt(y=harmonic)\n",
    "    percussive_tempo, _ = librosa.beat.beat_track(y=percussive)\n",
    "\n",
    "    return tonnetz, chroma, harmonic_chroma, percussive_tempo\n",
    "\n",
    "tonnetzs = []\n",
    "chromas = []\n",
    "harmonic_chromas = []\n",
    "percussive_tempos = []\n",
    "\n",
    "for i in range(0, len(time_series)):\n",
    "    tonnetz, chroma, harmonic_chroma, percussive_tempo = evenMOREfeatures(time_series[i])\n",
    "    tonnetzs.append(tonnetz)\n",
    "    chromas.append(chroma)\n",
    "    harmonic_chromas.append(harmonic_chroma)\n",
    "    percussive_tempos.append(percussive_tempo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregate_more = []\n",
    "for feature in [tonnetzs, chromas, harmonic_chromas, percussive_tempos]:\n",
    "    mean, std, max, min = aggregate_features(feature)\n",
    "    aggregate_more.append(mean)\n",
    "    aggregate_more.append(std)\n",
    "    aggregate_more.append(max)\n",
    "    aggregate_more.append(min)\n",
    "    \n",
    "for aggregate in aggregate_more:\n",
    "    save_features(aggregate, 'feature_' + str(i))\n",
    "    feature_count += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def more_features(series):\n",
    "    \"\"\"\n",
    "    Uses Librosa to extract features from the time series.\n",
    "    series: list of floats\n",
    "    returns:\n",
    "    mfcc_delta: the change in mfcc\n",
    "    \"\"\"\n",
    "    mfcc_delta = librosa.feature.delta(librosa.feature.mfcc(y=series))\n",
    "\n",
    "    return mfcc_delta\n",
    "\n",
    "mfcc_deltas = []\n",
    "\n",
    "for i in range(0, len(time_series)):\n",
    "    mfcc_delta = more_features(time_series[i])\n",
    "    mfcc_deltas.append(mfcc_delta)\n",
    "\n",
    "aggregate_mfcc_delta = []\n",
    "for feature in [mfcc_deltas]:\n",
    "    mean, std, max, min = aggregate_features(feature)\n",
    "    aggregate_mfcc_delta.append(mean)\n",
    "    aggregate_mfcc_delta.append(std)\n",
    "    aggregate_mfcc_delta.append(max)\n",
    "    aggregate_mfcc_delta.append(min)\n",
    "feature_count = 61\n",
    "for aggregate in aggregate_mfcc_delta:\n",
    "    save_features(aggregate, 'feature_' + str(feature_count))\n",
    "    feature_count += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
